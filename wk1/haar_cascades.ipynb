{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Title Section -->\n",
    "<div style=\"display: flex; align-items: center; justify-content: center; border-bottom: 4px solid black; padding-bottom: 10px; margin-bottom: 20px; height: 100px;\">\n",
    "  <h1 style=\"font-family: 'Times New Roman', serif; font-size: 32px; white-space: nowrap; overflow: hidden; text-overflow: ellipsis; margin-right: 10px;\">Sydney University Artificial Intelligence Association</h1>\n",
    "  <img src=\"https://usu.edu.au/_gatsby/file/7111e770ffabd38cfe1252cefb30461d/linkedin-1.png?u=https%3A%2F%2Fusu.wpengine.com%2Fwp-content%2Fuploads%2F2025%2F02%2Flinkedin-1.png\"/>\n",
    "</div>\n",
    "\n",
    "<h2>Workshop 1 - Cascade Classifier with OpenCV</h2>\n",
    "\n",
    "<!-- OpenCV Section -->\n",
    "<div style=\"max-width: 800px; margin-bottom: 40px;\">\n",
    "  <h3>What is OpenCV?</h3>\n",
    "\n",
    "  <!-- OpenCV logo + Wrapped Text -->\n",
    "  <img src=\"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRTu1OmEFc5Dx8-_lQv555XmUisLUI1S0DK-w&s\"\n",
    "  width=\"200\"\n",
    "  style=\"float: left; margin-right: 20px; border-right: 2px solid black; padding-right: 20px;\"/>\n",
    "\n",
    "  <p style=\"text-align: justify;\">\n",
    "  <b>Open Source Computer Vision Library</b>, or commonly known as <b>OpenCV</b>, is a computer vision and machine learning open-source library.\n",
    "  It is an expansive library capable of complex video processing and object detection capabilities.\n",
    "  </p>\n",
    "  <p style=\"text-align: justify;\">\n",
    "  To get the <a href=\"https://opencv.org/get-started/\">OpenCV</a> software library click on the link and download according to your system. Ask the tutor for assistance if you run into trouble!\n",
    "  </p>\n",
    "  <p style=\"text-align: justify;\">\n",
    "  If you wish to know more about OpenCV, read the <a href=\"https://opencv.org/about/\">official website</a> or a <a href=\"https://www.geeksforgeeks.org/opencv-overview/\">geeksforgeeks</a> summary\n",
    "  <!-- Clear the float to avoid layout breaking -->\n",
    "  <div style=\"clear: both;\"></div>\n",
    "</div>\n",
    "\n",
    "<!-- Haar Cascade Section -->\n",
    "<div style=\"max-width: 800px; margin-bottom: 40px;\">\n",
    "  <h4>Haar Cascade Object Detection</h4>\n",
    "\n",
    "  <!-- Haar Cascade Text -->\n",
    "  <p style=\"text-align: justify;\">\n",
    "  Haar feature-based cascade classifiers was first introduced by <a href=\"https://ieeexplore.ieee.org/document/990517\">Viola and Jones</a> in their 2001 publication <i>'Rapid object detection using a boosted cascade of simple features'</i>, and is an effective object detection algorithm notable for its fast detection capabilities. In a nutshell, the algorithm slides a window which extracts Haar features as shown below. These simplify features by taking the difference of the pixel sum of light and dark regions. Once the features are grouped, the algorithm will apply stages to distinguish regions of interest from background regions.\n",
    "  </p>\n",
    "  <!-- Haar Cascade Image -->\n",
    "  <div style=\"text-align: center; margin-top: 20px; margin-bottom: 20px;\">\n",
    "    <img src=\"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQmTo0e9DGxDCXowWRS_0KPcsfgT80yBE8klQ&s\" width=\"500\"/>\n",
    "  </div>\n",
    "  <p style=\"text-align: justify;\">\n",
    "  If you are interested in a detailed explanation go to <a href=\"https://docs.opencv.org/4.x/db/d28/tutorial_cascade_classifier.html\">OpenCV</a> documentation or read <a href=\"https://www.geeksforgeeks.org/face-detection-using-cascade-classifier-using-opencv-python/\">GeeksforGeeks</a>' comprehensive guide.\n",
    "  </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Real-time face detection with python\n",
    "<p>Now that we know what library and algorithm we will use to detect faces, lets get hands-on with its implementation using Python!</p>\n",
    "<p>First, make sure to import the necessary libraries:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.11.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "print(cv2.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Once you have sucessfully imported the libraries, make sure you have the pre-trained <a href=\"https://github.com/opencv/opencv/tree/master/data/haarcascades\">Haar cascades</a>.\n",
    "</p>\n",
    "<p>The pre-trained models should come with the installation of OpenCV, so the approach below should work if that is the case. If there are problems finding them, ask your tutor for help.</p>\n",
    "<p>I decided to use a dictionary to store the model files for each feature and obtain the full path using <code>cv2.data.haarcascades</code>, which provides the base directory.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'face': '/home/fernando/.local/lib/python3.12/site-packages/cv2/data/haarcascade_frontalface_default.xml', 'eyes': '/home/fernando/.local/lib/python3.12/site-packages/cv2/data/haarcascade_eye.xml'}\n"
     ]
    }
   ],
   "source": [
    "# Get cv2 default haarcascade directory\n",
    "data_dir = cv2.data.haarcascades\n",
    "\n",
    "# Define paths to different haarcascade models\n",
    "cascade_names = {\n",
    "    \"face\": \"haarcascade_frontalface_default.xml\", \n",
    "    \"eyes\": \"haarcascade_eye.xml\"\n",
    "    # \"mouth\": \"haarcascade_mcs_mouth.xml\", \n",
    "    # \"nose\": \"haarcascade_mcs_nose.xml\"\n",
    "}\n",
    "cascade_path = {roi: os.path.join(data_dir, filename) for roi, filename in cascade_names.items()}\n",
    "\n",
    "print(cascade_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Loading the pre-trained Haar cascades is straight-forward, for each feature create a <code>CascadeClassifier()</code> object and load it using the <code>load()</code> method.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--(*)Haar cascades loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "#-- 1. Load the cascades\n",
    "cascades = {}\n",
    "for roi, path in cascade_path.items():\n",
    "    if not os.path.exists(path): # Check if the file exists\n",
    "        print(f\"--(!)Warning: {roi} cascade not found at {path}, Skipping...\")\n",
    "        continue # Skip cascade if file is missing\n",
    "\n",
    "    classifier = cv2.CascadeClassifier()\n",
    "    if not classifier.load(path):\n",
    "        print(f'--(X)Error loading {roi} cascade at {path}')\n",
    "        exit(0)\n",
    "    cascades[roi] = classifier\n",
    "print(\"--(*)Haar cascades loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The loaded Haar cascade can then make predictions using <code>detectMultiScale()</code> method, which returns boundary rectangles for the ROI.</p>\n",
    "<p>The function <code>detect()</code> will process the frame by returning bounding boxes for the faces which then can be used to apply the Haar cascades for the eyes and other facial features.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect(frame):\n",
    "    # Convert the frame into grayscale and equalize\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    frame_gray = cv2.equalizeHist(frame_gray)\n",
    "\n",
    "    #-- Detect faces\n",
    "    faces = cascades['face'].detectMultiScale(\n",
    "        frame_gray,\n",
    "        scaleFactor=1.05,\n",
    "        minNeighbors=5,\n",
    "        minSize=(30, 30),\n",
    "        flags=cv2.CASCADE_SCALE_IMAGE\n",
    "        )\n",
    "    # Loop over the bounding box for each face\n",
    "    for (x,y,w,h) in faces:\n",
    "        # Obtain the center and draw an ellipse around the face\n",
    "        center = (x + w//2, y + h//2)\n",
    "        frame = cv2.ellipse(frame, center, (w//2, h//2), 0, 0, 360, (255, 0, 255), 4)\n",
    "        face_roi = frame_gray[y:y+h, x:x+w]\n",
    "        #-- In each face, detect eyes\n",
    "        eyes = cascades['eyes'].detectMultiScale(\n",
    "            face_roi,\n",
    "            scaleFactor=1.1,\n",
    "            minNeighbors=10,\n",
    "            minSize=(15, 15),\n",
    "            flags=cv2.CASCADE_SCALE_IMAGE\n",
    "            )\n",
    "        # Loop over the bounding box for the eyes relative to the original frame dimensions \n",
    "        for (x2, y2, w2, h2) in eyes:\n",
    "            ptA = (x + x2, y + y2)\n",
    "            ptB = (x + x2 + w2, y + y2 + h2)\n",
    "            # Draw rectangles around the eyes\n",
    "            cv2.rectangle(frame, ptA, ptB, (0, 0, 255), 2)\n",
    "    cv2.imshow('Capture - Face detection', frame) # Show frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Finally, we can visualize our output using <b>OpenCV's</b> video stream as follows:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--(!) No captured frame -- Break!\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#-- 2. Read the video stream\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened:\n",
    "    print(\"--(X)Error opening video capture\")\n",
    "    exit(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if frame is None:\n",
    "        print(\"--(!) No captured frame -- Break!\")\n",
    "        break\n",
    "    detect(frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows() # Clean-up"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
